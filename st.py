import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import io
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
from statsmodels.tsa.arima.model import ARIMA
from prophet import Prophet
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score
from sklearn.model_selection import train_test_split

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤",
    page_icon="üìà",
    layout="wide"
)

# –°—Ç–∏–ª–∏ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #3B82F6;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #F8FAFC;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #3B82F6;
        margin-bottom: 1rem;
    }
    .success-text { color: #10B981; }
    .warning-text { color: #F59E0B; }
    .error-text { color: #EF4444; }
</style>
""", unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.markdown('<h1 class="main-header">üìà –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤</h1>', unsafe_allow_html=True)
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2103/2103655.png", width=100)
    st.markdown("### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    uploaded_file = st.file_uploader("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/Excel —Ñ–∞–π–ª", type=['csv', 'xlsx', 'xls'])
    
    st.markdown("---")
    st.markdown("### üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    
    date_column = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –¥–∞—Ç–æ–π", value="Order Date")
    value_column = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π", value="Sales")
    
    frequency = st.selectbox(
        "–ß–∞—Å—Ç–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö",
        ["D (–µ–∂–µ–¥–Ω–µ–≤–Ω–æ)", "W (–µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ)", "M (–µ–∂–µ–º–µ—Å—è—á–Ω–æ)", "Q (–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ)", "Y (–µ–∂–µ–≥–æ–¥–Ω–æ)"]
    )
    
    freq_map = {"D (–µ–∂–µ–¥–Ω–µ–≤–Ω–æ)": "D", "W (–µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ)": "W", 
                "M (–µ–∂–µ–º–µ—Å—è—á–Ω–æ)": "M", "Q (–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ)": "Q", "Y (–µ–∂–µ–≥–æ–¥–Ω–æ)": "Y"}
    selected_freq = freq_map[frequency]
    
    forecast_periods = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞", 1, 52, 12)
    
    st.markdown("---")
    st.markdown("### ü§ñ –ú–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    use_arima = st.checkbox("ARIMA", value=True)
    use_prophet = st.checkbox("Prophet", value=True)
    use_rf = st.checkbox("Random Forest", value=True)
    
    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ", type="primary", use_container_width=True):
        st.session_state.run_forecast = True

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
def load_data(file):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return None

def prepare_time_series(df, date_col, value_col, freq='W'):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"""
    df = df.copy()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç—ã
    df[date_col] = pd.to_datetime(df[date_col])
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ
    df['period'] = df[date_col].dt.to_period(freq).dt.start_time
    ts = df.groupby('period')[value_col].sum().reset_index()
    ts.columns = ['ds', 'y']
    
    return ts

def create_features_for_rf(series, n_lags=12):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è Random Forest"""
    df = pd.DataFrame({'y': series})
    
    # –õ–∞–≥–∏
    for lag in range(1, n_lags + 1):
        df[f'lag_{lag}'] = df['y'].shift(lag)
    
    # –°–∫–æ–ª—å–∑—è—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    for window in [3, 6, 12]:
        df[f'rolling_mean_{window}'] = df['y'].rolling(window=window, min_periods=1).mean()
        df[f'rolling_std_{window}'] = df['y'].rolling(window=window, min_periods=1).std()
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['month'] = df.index.month
    df['quarter'] = df.index.quarter
    
    return df.dropna()

# –§—É–Ω–∫—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
def run_arima(train_data, periods):
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ ARIMA"""
    try:
        model = ARIMA(train_data['y'], order=(1,1,1))
        model_fit = model.fit()
        forecast = model_fit.forecast(steps=periods)
        return forecast, model_fit
    except Exception as e:
        st.warning(f"ARIMA –æ—à–∏–±–∫–∞: {e}")
        return None, None

def run_prophet(train_data, periods):
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ Prophet"""
    try:
        model = Prophet(yearly_seasonality=True, weekly_seasonality=True if len(train_data) > 7 else False)
        model.fit(train_data)
        
        future = model.make_future_dataframe(periods=periods, freq=selected_freq)
        forecast = model.predict(future)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        forecast_values = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(periods)
        return forecast_values, model
    except Exception as e:
        st.warning(f"Prophet –æ—à–∏–±–∫–∞: {e}")
        return None, None

def run_random_forest(train_data, periods):
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ Random Forest"""
    try:
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_df = create_features_for_rf(train_data['y'].values)
        
        if len(features_df) < 20:
            st.warning("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Random Forest")
            return None, None
        
        X = features_df.drop('y', axis=1)
        y = features_df['y']
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
        
        # –ú–æ–¥–µ–ª—å
        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)
        
        # –ü—Ä–æ–≥–Ω–æ–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        last_features = X.iloc[-1:].values
        forecasts = []
        
        for _ in range(periods):
            pred = model.predict(last_features)[0]
            forecasts.append(pred)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
            last_features = np.roll(last_features, 1)
            last_features[0, 0] = pred
        
        return forecasts, model
    except Exception as e:
        st.warning(f"Random Forest –æ—à–∏–±–∫–∞: {e}")
        return None, None

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
if uploaded_file is not None:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data(uploaded_file)
    
    if df is not None:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown('<h3 class="sub-header">üìä –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö</h3>', unsafe_allow_html=True)
            st.dataframe(df.head(10), use_container_width=True)
        
        with col2:
            st.markdown('<h3 class="sub-header">üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö</h3>', unsafe_allow_html=True)
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫", len(df))
            st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤", len(df.columns))
            
            if date_column in df.columns:
                date_info = pd.to_datetime(df[date_column])
                st.metric("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", f"{date_info.min().date()} - {date_info.max().date()}")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
        ts_data = prepare_time_series(df, date_column, value_column, selected_freq)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        st.markdown('<h3 class="sub-header">üìà –ò—Å—Ö–æ–¥–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥</h3>', unsafe_allow_html=True)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=ts_data['ds'],
            y=ts_data['y'],
            mode='lines+markers',
            name='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ',
            line=dict(color='#3B82F6', width=2)
        ))
        
        fig.update_layout(
            title="–î–∏–Ω–∞–º–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞",
            xaxis_title="–î–∞—Ç–∞",
            yaxis_title=value_column,
            hovermode='x unified',
            template='plotly_white'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        train_size = int(len(ts_data) * 0.8)
        train_data = ts_data.iloc[:train_size]
        test_data = ts_data.iloc[train_size:]
        
        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if 'run_forecast' in st.session_state and st.session_state.run_forecast:
            st.markdown("---")
            st.markdown('<h2 class="main-header">üîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è</h2>', unsafe_allow_html=True)
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            results = {}
            models = {}
            
            # –ó–∞–ø—É—Å–∫ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            models_to_run = []
            if use_arima: models_to_run.append(('ARIMA', run_arima))
            if use_prophet: models_to_run.append(('Prophet', run_prophet))
            if use_rf: models_to_run.append(('Random Forest', run_random_forest))
            
            for i, (model_name, model_func) in enumerate(models_to_run):
                status_text.text(f"üîÑ –û–±—É—á–µ–Ω–∏–µ {model_name}...")
                forecast, model = model_func(train_data, forecast_periods)
                
                if forecast is not None:
                    results[model_name] = forecast
                    models[model_name] = model
                
                progress_bar.progress((i + 1) / len(models_to_run))
            
            status_text.text("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            if results:
                st.markdown('<h3 class="sub-header">üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤</h3>', unsafe_allow_html=True)
                
                fig_forecast = go.Figure()
                
                # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
                fig_forecast.add_trace(go.Scatter(
                    x=ts_data['ds'],
                    y=ts_data['y'],
                    mode='lines',
                    name='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ',
                    line=dict(color='#3B82F6', width=2)
                ))
                
                # –ü—Ä–æ–≥–Ω–æ–∑—ã –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                colors = {'ARIMA': '#10B981', 'Prophet': '#F59E0B', 'Random Forest': '#EF4444'}
                
                for model_name, forecast in results.items():
                    if model_name == 'Prophet' and hasattr(forecast, 'columns'):
                        # Prophet –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame
                        fig_forecast.add_trace(go.Scatter(
                            x=forecast['ds'],
                            y=forecast['yhat'],
                            mode='lines',
                            name=f'{model_name} –ø—Ä–æ–≥–Ω–æ–∑',
                            line=dict(color=colors.get(model_name, '#000'), width=2, dash='dash')
                        ))
                        
                        # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è Prophet
                        fig_forecast.add_trace(go.Scatter(
                            x=forecast['ds'].tolist() + forecast['ds'].tolist()[::-1],
                            y=forecast['yhat_upper'].tolist() + forecast['yhat_lower'].tolist()[::-1],
                            fill='toself',
                            fillcolor='rgba(245, 158, 11, 0.2)',
                            line=dict(color='rgba(255,255,255,0)'),
                            name=f'{model_name} –¥–æ–≤. –∏–Ω—Ç–µ—Ä–≤–∞–ª',
                            showlegend=True if model_name == 'Prophet' else False
                        ))
                    else:
                        # ARIMA –∏ Random Forest
                        forecast_dates = pd.date_range(
                            start=ts_data['ds'].iloc[-1] + pd.Timedelta(days=1),
                            periods=forecast_periods,
                            freq=selected_freq
                        )
                        
                        fig_forecast.add_trace(go.Scatter(
                            x=forecast_dates,
                            y=forecast,
                            mode='lines',
                            name=f'{model_name} –ø—Ä–æ–≥–Ω–æ–∑',
                            line=dict(color=colors.get(model_name, '#000'), width=2, dash='dash')
                        ))
                
                fig_forecast.update_layout(
                    title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π",
                    xaxis_title="–î–∞—Ç–∞",
                    yaxis_title=value_column,
                    hovermode='x unified',
                    template='plotly_white',
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )
                
                st.plotly_chart(fig_forecast, use_container_width=True)
                
                # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)
                if len(test_data) > 0:
                    st.markdown('<h3 class="sub-header">üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π</h3>', unsafe_allow_html=True)
                    
                    metrics_data = []
                    
                    for model_name, forecast in results.items():
                        if len(forecast) >= len(test_data):
                            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ n –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —Ç–µ—Å—Ç–æ–º
                            forecast_for_test = forecast[:len(test_data)]
                            
                            if isinstance(forecast_for_test, pd.DataFrame):
                                forecast_values = forecast_for_test['yhat'].values
                            else:
                                forecast_values = forecast_for_test
                            
                            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                            mae = mean_absolute_error(test_data['y'].values, forecast_values)
                            mape = mean_absolute_percentage_error(test_data['y'].values, forecast_values) * 100
                            r2 = r2_score(test_data['y'].values, forecast_values)
                            
                            metrics_data.append({
                                '–ú–æ–¥–µ–ª—å': model_name,
                                'MAE': mae,
                                'MAPE (%)': mape,
                                'R¬≤': r2,
                                '–°—Ç–∞—Ç—É—Å': '‚úÖ –•–æ—Ä–æ—à–æ' if mape < 20 else '‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ' if mape < 50 else '‚ùå –ü–ª–æ—Ö–æ'
                            })
                    
                    if metrics_data:
                        metrics_df = pd.DataFrame(metrics_data)
                        
                        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ –∫–∞—Ä—Ç–æ—á–µ–∫
                        cols = st.columns(len(metrics_data))
                        
                        for idx, row in metrics_df.iterrows():
                            with cols[idx]:
                                st.markdown(f'<div class="metric-card">', unsafe_allow_html=True)
                                st.markdown(f"**{row['–ú–æ–¥–µ–ª—å']}**")
                                st.metric("MAE", f"{row['MAE']:.2f}")
                                st.metric("MAPE", f"{row['MAPE (%)']:.1f}%")
                                st.metric("R¬≤", f"{row['R¬≤']:.3f}")
                                st.markdown(f"**–°—Ç–∞—Ç—É—Å:** {row['–°—Ç–∞—Ç—É—Å']}")
                                st.markdown('</div>', unsafe_allow_html=True)
                        
                        # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–µ—Ç–∞–ª—è–º–∏
                        st.dataframe(metrics_df, use_container_width=True)
                
                # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.markdown('<h3 class="sub-header">üìù –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</h3>', unsafe_allow_html=True)
                
                interpretation_cols = st.columns(2)
                
                with interpretation_cols[0]:
                    st.markdown("### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏")
                    
                    if 'ARIMA' in results:
                        st.markdown("""
                        **ARIMA** –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:
                        - –°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                        - –ö–æ—Ä–æ—Ç–∫–∏—Ö –∏ —Å—Ä–µ–¥–Ω–∏—Ö –≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
                        - –î–∞–Ω–Ω—ã—Ö –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö —Å–µ–∑–æ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                        """)
                    
                    if 'Prophet' in results:
                        st.markdown("""
                        **Prophet** –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:
                        - –î–∞–Ω–Ω—ã—Ö —Å —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é (–Ω–µ–¥–µ–ª—å–Ω–æ–π, –≥–æ–¥–æ–≤–æ–π)
                        - –£—á–µ—Ç–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö
                        - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤
                        """)
                    
                    if 'Random Forest' in results:
                        st.markdown("""
                        **Random Forest** –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:
                        - –î–∞–Ω–Ω—ã—Ö —Å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
                        - –ë–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö
                        - –ö–æ–≥–¥–∞ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                        """)
                
                with interpretation_cols[1]:
                    st.markdown("### üí° –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                    
                    recommendations = []
                    
                    if any('MAPE (%)' in str(m) for m in metrics_data if isinstance(m, dict)):
                        avg_mape = np.mean([m.get('MAPE (%)', 0) for m in metrics_data if isinstance(m, dict)])
                        
                        if avg_mape < 10:
                            recommendations.append("‚úÖ **–û—Ç–ª–∏—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
                        elif avg_mape < 20:
                            recommendations.append("‚ö†Ô∏è **–•–æ—Ä–æ—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")
                        elif avg_mape < 30:
                            recommendations.append("üìä **–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –Ω—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
                        else:
                            recommendations.append("üîß **–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã –∏–ª–∏ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
                    
                    recommendations.append("üìà **–°–æ–±–∏—Ä–∞–π—Ç–µ –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö** –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏")
                    recommendations.append("üîÑ **–†–µ–≥—É–ª—è—Ä–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∞–π—Ç–µ –º–æ–¥–µ–ª–∏** –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                    recommendations.append("üéØ **–ö–æ–º–±–∏–Ω–∏—Ä—É–π—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑—ã** —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
                    
                    for rec in recommendations:
                        st.markdown(f"- {rec}")
                
                # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.markdown('<h3 class="sub-header">üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</h3>', unsafe_allow_html=True)
                
                export_cols = st.columns(3)
                
                with export_cols[0]:
                    if st.button("üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã CSV", use_container_width=True):
                        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
                        forecast_dates = pd.date_range(
                            start=ts_data['ds'].iloc[-1] + pd.Timedelta(days=1),
                            periods=forecast_periods,
                            freq=selected_freq
                        )
                        
                        forecast_df = pd.DataFrame({'–î–∞—Ç–∞': forecast_dates})
                        
                        for model_name, forecast in results.items():
                            if isinstance(forecast, pd.DataFrame):
                                forecast_df[model_name] = forecast['yhat'].values
                            else:
                                forecast_df[model_name] = forecast
                        
                        csv = forecast_df.to_csv(index=False)
                        st.download_button(
                            label="–ù–∞–∂–º–∏—Ç–µ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è",
                            data=csv,
                            file_name="–ø—Ä–æ–≥–Ω–æ–∑—ã_–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ_—Ä—è–¥–∞.csv",
                            mime="text/csv"
                        )
                
                with export_cols[1]:
                    if st.button("üìä –°–∫–∞—á–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫", use_container_width=True):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
                        fig_forecast.write_html("–ø—Ä–æ–≥–Ω–æ–∑—ã_–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ_—Ä—è–¥–∞.html")
                        with open("–ø—Ä–æ–≥–Ω–æ–∑—ã_–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ_—Ä—è–¥–∞.html", "rb") as file:
                            st.download_button(
                                label="–ù–∞–∂–º–∏—Ç–µ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è",
                                data=file,
                                file_name="–ø—Ä–æ–≥–Ω–æ–∑—ã_–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ_—Ä—è–¥–∞.html",
                                mime="text/html"
                            )
                
                with export_cols[2]:
                    if st.button("üìã –û—Ç—á–µ—Ç –≤ PDF", use_container_width=True):
                        st.info("–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF –æ—Ç—á–µ—Ç–∞ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")
            
            else:
                st.warning("–ù–∏ –æ–¥–Ω–∞ –∏–∑ –º–æ–¥–µ–ª–µ–π –Ω–µ —Å–º–æ–≥–ª–∞ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        
        else:
            st.info("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É 'üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ' –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏")
    
else:
    # –î–µ–º–æ-—Ä–µ–∂–∏–º
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### üìã –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
        st.markdown("""
        –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ –æ–¥–Ω–æ–º –∏–∑ —Ñ–æ—Ä–º–∞—Ç–æ–≤:
        
        **CSV/Excel —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:**
        - –î–∞—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '2024-01-01')
        - –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–ø—Ä–æ–¥–∞–∂–∏, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏ —Ç.–¥.)
        
        **–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:**
        """)
        
        example_df = pd.DataFrame({
            'Order Date': pd.date_range('2024-01-01', periods=10, freq='D'),
            'Sales': [100, 120, 130, 110, 140, 150, 160, 170, 180, 190]
        })
        st.dataframe(example_df, use_container_width=True)
    
    with col2:
        st.markdown("### üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
        st.markdown("""
        ‚úÖ **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π:**
        - ARIMA (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        - Prophet (–æ—Ç Facebook)
        - Random Forest (–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ)
        
        ‚úÖ **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:**
        - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
        - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        - –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        
        ‚úÖ **–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**
        - CSV —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
        - HTML –≥—Ä–∞—Ñ–∏–∫–∏
        - –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        """)
        
        st.markdown("### ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç")
        st.markdown("""
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏
        2. –£–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
        3. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏
        4. –ù–∞–∂–º–∏—Ç–µ "–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ"
        """)

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #6B7280;'>"
    "üìä –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ | –°–æ–∑–¥–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é Streamlit"
    "</div>",
    unsafe_allow_html=True
)